{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "664499a1-deca-4624-9cba-f0948ba7721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from torch import nn\n",
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import bert_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74669b07-c772-45cb-8e05-eddbf8b94801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert df to needed format\n",
    "path = \"Train_Tagged_Titles.tsv\"\n",
    "df = pd.read_csv(path, sep=\"\\t\", dtype=str, keep_default_na=False, na_values=[\"\"], quoting=csv.QUOTE_NONE)\n",
    "df[\"Record Number\"] = df[\"Record Number\"].astype(int)\n",
    "# forward fill NaN values with last valid value\n",
    "df = df.ffill()\n",
    "train_df = bert_ner.convert_df(df)\n",
    "\n",
    "# put in dataet\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-german-cased')\n",
    "train_dl, labels2id, id2labels, train_ds = bert_ner.create_dl(train_df, df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "802ae6e1-5e59-4059-bbf1-fd3008f3128c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model + weights\n",
    "model = BertForTokenClassification.from_pretrained( \\\n",
    "    'bert-base-german-cased', num_labels=len(labels2id), id2label=id2labels, label2id=labels2id)\n",
    "d = torch.load('bert_german_0.p', map_location=torch.device('cpu'))\n",
    "model.load_state_dict(d['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d68175a-0bf9-41b3-ae7a-0b4e51161dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[CLS]', 'O'),\n",
       " ('Supreme', 'Modell'),\n",
       " ('Nike', 'Marke'),\n",
       " ('SB Dunk', 'Produktlinie'),\n",
       " ('High', 'Schuhschaft-Typ'),\n",
       " ('By any Means', 'Modell'),\n",
       " ('Red', 'Farbe'),\n",
       " ('US10', 'US-Schuhgröße'),\n",
       " ('EU44', 'EU-Schuhgröße'),\n",
       " ('Supreme Box', 'No Tag'),\n",
       " ('Logo', 'Akzente'),\n",
       " ('Air Force', 'Produktlinie'),\n",
       " ('[SEP]', 'O')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample out\n",
    "decoder = bert_ner.NERDecoder(tokenizer, id2labels)\n",
    "decoder.decode(train_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c00523-f9a9-45ba-9f63-fa5467b56e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
